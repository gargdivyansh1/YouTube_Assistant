# YouTube Assistant - AI-Powered Video Knowledge Engine

**YouTube Assistant** brings advanced, AI-powered conversational understanding to every YouTube video through a seamless browser extension and a sophisticated, scalable backend. It's more than just a Q&A bot: it's an extensible, distributed knowledge infrastructure for the world's video content.

> **Transform any YouTube video into an interactive knowledge source with AI-powered question answering, voice recognition, and planetary-scale vector caching.**

---

## Table of Contents

1. [Overview](#overview)
2. [Key Innovation: Planet-Scale Vector Caching](#key-innovation-planet-scale-vector-caching)
3. [Features](#features)
4. [Technology Stack](#technology-stack)
5. [Architecture](#architecture)
6. [System Design](#system-design)
7. [Setup & Installation](#setup--installation)
8. [Configuration](#configuration)
9. [API Reference](#api-reference)
10. [Advanced Topics](#advanced-topics)
11. [Troubleshooting](#troubleshooting)
12. [Contributing](#contributing)
13. [Acknowledgements](#acknowledgements)

---

## Overview

YouTube Assistant enables users to ask **any question** about any YouTube video and receive **context-rich, intelligent answers** directly within the YouTube interface. Unlike simple transcript overlays or generic AI chatbots, this assistant:

- **Processes video content once** and makes it available to millions of users
- **Understands context** through semantic embeddings and retrieval-augmented generation  
- **Supports multi-turn conversations** with full chat history awareness
- **Handles both broad and specific queries** with intelligent query classification
- **Works offline from captions** using automatic speech recognition (ASR) when needed
- **Scales globally** with a single vector cache per video serving unlimited users

### Real-World Use Cases

- ğŸ“š **Educational Content**: Students ask questions about lecture videos, tutorials, and educational content
- ğŸ¬ **Entertainment**: Viewers get deep explanations about plot, characters, and production details
- ğŸµ **Music & Poetry**: Detailed analysis of lyrics, musical themes, and poetic meaning
- ğŸ“° **News & Analysis**: Context-aware analysis of breaking news, interviews, and documentaries
- ğŸ”¬ **Technical Tutorials**: Step-by-step explanations for programming, design, and technical how-tos

---

## Key Innovation: Planet-Scale Vector Caching

### The Problem It Solves

Without vector caching, if a viral YouTube video gets 100 million views:
- Every user query causes transcription
- Every query triggers embedding computation
- Costs scale linearly with user count (millions of dollars)
- Each user experiences 30-60 second latency

### The Solution

YouTube Assistant implements one-time processing with infinite distribution:

```
First User Queries Video â†’ Transcript Fetched â†’ Embeddings Computed & Cached
                                                        â†“
           Users 2, 3...1M all use SAME cached data instantly
```

**Key Benefits:**

| Benefit | Impact |
|---------|--------|
| **One-Time Processing** | Transcription & embedding happens once per video |
| **Infinite Scalability** | 1 user or 1 billion users = same cost |
| **99.9% Cost Reduction** | Popular videos cost nearly nothing after first request |
| **Sub-100ms Response** | All users after first get instant, cached answers |
| **Global Knowledge Graph** | Shared intelligence across all users worldwide |

---

## Features

### Core Capabilities
- âœ… **Universal Video Support**: Works with watch pages, shorts, embedded videos
- âœ… **Smart Transcript Retrieval**: Official captions when available; ASR fallback for missing captions
- âœ… **Semantic Search**: Vector similarity finds most relevant video segments
- âœ… **Query Intelligence**: Broad queries (summarize) vs. specific (find X) handled optimally
- âœ… **Session-Based Chat Memory**: Multi-turn conversations with full context awareness
- âœ… **Voice I/O**: Web Speech API for hands-free queries and synthesized answers

### Technical Features
- âœ… **Efficient Audio Chunking**: Large videos split into 5-minute segments
- âœ… **Overlapping Text Chunks**: Preserves context across boundaries
- âœ… **Multi-Language Support**: 11+ languages (English, Hindi, Spanish, French, German, Russian, Portuguese, Japanese, Korean, Mandarin, Arabic)
- âœ… **CORS-Enabled**: Seamless extension-to-backend communication
- âœ… **Namespace Isolation**: Each video has isolated vector space
- âœ… **Chat Persistence**: In-memory chat history per session

### User Experience
- âœ… **Floating Widget**: Non-intrusive, draggable, minimizable UI
- âœ… **Real-Time Feedback**: Character counter, loading animations
- âœ… **Dark Theme**: Optimized for YouTube interface
- âœ… **Error Handling**: Graceful degradation when APIs unavailable

---

## Technology Stack

### Backend

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **Server** | FastAPI (Python 3.8+) | High-performance async API |
| **LLM** | OpenAI GPT-4o-mini | Answer generation |
| **Embeddings** | OpenAI text-embedding-ada-002 | Semantic vectors (1536-dim) |
| **Vector DB** | Pinecone | Distributed vector storage |
| **Orchestration** | LangChain | Chain composition, memory |
| **Transcripts** | youtube-transcript-api | Official YouTube captions |
| **Audio Download** | yt-dlp | Best audio extraction |
| **Speech Recognition** | faster-whisper | Efficient ASR (CPU-friendly) |
| **Audio Processing** | pydub | Audio splitting/conversion |
| **Text Splitting** | LangChain RecursiveCharacterTextSplitter | Intelligent chunking |
| **Environment** | python-dotenv | Secure configuration |

### Frontend (Chrome Extension)

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **Manifest** | Manifest v3 | Chrome extension API |
| **Content Script** | Vanilla JavaScript | DOM injection, UI rendering |
| **Background Worker** | Vanilla JavaScript | Message relay, API communication |
| **Styling** | Pure CSS | Dark theme, responsive design |
| **Voice Recognition** | Web Speech API | SpeechRecognition API |
| **Text-to-Speech** | Web Speech API | SpeechSynthesis API |

### Infrastructure

| Service | Purpose | Cost |
|---------|---------|------|
| **OpenAI API** | LLM + Embeddings | ~$0.02-0.05 per video (first request) |
| **Pinecone** | Vector Database | ~$0.01-0.10 per video (cached) |
| **Hosting** | Backend Server | Free tier (Render) to $10+/month |

---

## Architecture

### System Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              YouTube Website (youtube.com)                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚    Chrome Extension - Content Script (content.js)    â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚   â”‚
â”‚  â”‚  â”‚  â€¢ Floating UI Widget                        â”‚    â”‚   â”‚
â”‚  â”‚  â”‚  â€¢ Video ID Detection                        â”‚    â”‚   â”‚
â”‚  â”‚  â”‚  â€¢ Voice Input (Web Speech API)              â”‚    â”‚   â”‚
â”‚  â”‚  â”‚  â€¢ Message Relay to Background Worker        â”‚    â”‚   â”‚
â”‚  â”‚  â”‚  â€¢ Answer Rendering + Voice Output           â”‚    â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚              â†“ chrome.runtime.sendMessage()                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Background Service Worker (background.js)          â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚   â”‚
â”‚  â”‚  â”‚  â€¢ Receives messages from content script     â”‚    â”‚   â”‚
â”‚  â”‚  â”‚  â€¢ Sends POST /chat to backend               â”‚    â”‚   â”‚
â”‚  â”‚  â”‚  â€¢ Relays responses back                     â”‚    â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“ HTTP POST /chat (JSON)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            Backend Server - FastAPI (index.py)              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Request: {video_id, session_id, question}         â”‚   â”‚
â”‚  â”‚  â†“                                                   â”‚   â”‚
â”‚  â”‚  1. Check retriever_cache for video                â”‚   â”‚
â”‚  â”‚     Hit â†’ Use cached retriever                     â”‚   â”‚
â”‚  â”‚     Miss â†’ Continue to step 2                      â”‚   â”‚
â”‚  â”‚  â†“                                                   â”‚   â”‚
â”‚  â”‚  2. Fetch Transcript (main.py)                      â”‚   â”‚
â”‚  â”‚     â€¢ Try: YouTube Captions API                    â”‚   â”‚
â”‚  â”‚     â€¢ Except: yt-dlp â†’ whisper ASR                 â”‚   â”‚
â”‚  â”‚  â†“                                                   â”‚   â”‚
â”‚  â”‚  3. Chunk & Embed (main.py)                         â”‚   â”‚
â”‚  â”‚     â€¢ merge_and_split_segments()                   â”‚   â”‚
â”‚  â”‚     â€¢ OpenAI embeddings â†’ 1536-dim vectors         â”‚   â”‚
â”‚  â”‚     â€¢ Store in Pinecone (namespace=video_id)       â”‚   â”‚
â”‚  â”‚  â†“                                                   â”‚   â”‚
â”‚  â”‚  4. Classify Query (index.py)                       â”‚   â”‚
â”‚  â”‚     is_broad_query(question)?                      â”‚   â”‚
â”‚  â”‚  â†“                                                   â”‚   â”‚
â”‚  â”‚  5. Retrieve Context                                â”‚   â”‚
â”‚  â”‚     â€¢ Broad: Use full transcript                   â”‚   â”‚
â”‚  â”‚     â€¢ Specific: Vector similarity search (k=6)     â”‚   â”‚
â”‚  â”‚  â†“                                                   â”‚   â”‚
â”‚  â”‚  6. Generate Answer (main.py)                       â”‚   â”‚
â”‚  â”‚     â€¢ Get chat history from session_id              â”‚   â”‚
â”‚  â”‚     â€¢ Build prompt template                        â”‚   â”‚
â”‚  â”‚     â€¢ chain_with_memory.invoke()                   â”‚   â”‚
â”‚  â”‚     â€¢ GPT-4o-mini generates response               â”‚   â”‚
â”‚  â”‚  â†“                                                   â”‚   â”‚
â”‚  â”‚  Return ChatResponse: {"answer": "..."}           â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“ External APIs (Conditional)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     External Services                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ OpenAI API                             â”‚
â”‚   - LLM: gpt-4o-mini                    â”‚
â”‚   - Embeddings: ada-002                  â”‚
â”‚ â€¢ YouTube APIs                           â”‚
â”‚   - Transcript API (captions)            â”‚
â”‚   - Audio via yt-dlp                     â”‚
â”‚ â€¢ Pinecone                               â”‚
â”‚   - Vector database                      â”‚
â”‚   - Cosine similarity search             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Component Structure

```
youtube_assistant/
â”œâ”€â”€ README.md                    â† Quick start (you are here)
â”œâ”€â”€ README_DETAILED.md           â† Deep technical dive
â”œâ”€â”€ .env.sample                  â† Environment template
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                  â† Core logic
â”‚   â”‚   â”œâ”€â”€ get_transcript()           - Fetch captions OR transcode audio
â”‚   â”‚   â”œâ”€â”€ get_audio_from_youtube()   - Download audio via yt-dlp
â”‚   â”‚   â”œâ”€â”€ split_audio()              - Chunk large files (5-min chunks)
â”‚   â”‚   â”œâ”€â”€ merge_and_split_segments() - Semantic chunking
â”‚   â”‚   â”œâ”€â”€ chain_with_memory          - LangChain conversation chain
â”‚   â”‚   â””â”€â”€ get_session_history()      - Session memory management
â”‚   â”‚
â”‚   â”œâ”€â”€ index.py                 â† FastAPI server
â”‚   â”‚   â”œâ”€â”€ app = FastAPI()      - Application instance
â”‚   â”‚   â”œâ”€â”€ is_broad_query()     - Query classification
â”‚   â”‚   â”œâ”€â”€ POST /chat           - Main endpoint
â”‚   â”‚   â”œâ”€â”€ HEAD /uptime         - Health check
â”‚   â”‚   â”œâ”€â”€ retriever_cache      - Vectorstore cache
â”‚   â”‚   â””â”€â”€ transcript_cache     - Full transcript storage
â”‚   â”‚
â”‚   â”œâ”€â”€ requirements.txt          â† Python dependencies
â”‚   â””â”€â”€ __pycache__/
â”‚
â””â”€â”€ chrome_extension/
    â”œâ”€â”€ manifest.json            â† Extension config (v3)
    â”œâ”€â”€ content.js               â† Injected UI + logic
    â”œâ”€â”€ background.js            â† Message relay + API calls
    â””â”€â”€ icons/                   â† Extension icons
```

---

## System Design

### How It Works - Step by Step

```
1. USER TYPES QUESTION
   â””â”€â†’ "What is this video about?"

2. CONTENT SCRIPT CAPTURES
   â””â”€â†’ Extracts video_id, creates message object

3. BACKGROUND WORKER RECEIVES
   â””â”€â†’ Sends HTTP POST to backend /chat endpoint

4. BACKEND RECEIVES REQUEST
   â””â”€â†’ {video_id: "dQw4w9WgXcQ", question: "...", session_id: "..."}

5. CHECK CACHE
   â”œâ”€â†’ Cache HIT: Use stored retriever
   â””â”€â†’ Cache MISS: Continue to step 6

6. IF CACHE MISS: FETCH TRANSCRIPT
   â”œâ”€â†’ Try: youtube-transcript-api.fetch() 
   â”‚   â”œâ”€â†’ SUCCESS: Get captions in 11 languages
   â”‚   â””â”€â†’ COST: Free, <1 second
   â””â”€â†’ Except TranscriptsDisabled:
       â”œâ”€â†’ yt-dlp downloads best audio
       â”œâ”€â†’ Split if >25MB (5-min chunks)
       â”œâ”€â†’ faster-whisper transcribes
       â””â”€â†’ COST: Free, 5-10 min for 1-hour video

7. CHUNK & EMBED
   â”œâ”€â†’ merge_and_split_segments()
   â”œâ”€â†’ RecursiveCharacterTextSplitter (chunk_size=250, overlap=50)
   â”œâ”€â†’ OpenAI embeddings â†’ 1536-dim vectors
   â”œâ”€â†’ Store in Pinecone (namespace=video_id)
   â””â”€â†’ Cache for future requests

8. CLASSIFY QUERY
   â”œâ”€â†’ is_broad_query(question) â†’ Regex patterns
   â”œâ”€â†’ YES: Summarize, explain, what about, overview
   â””â”€â†’ NO: When, who, what does X mean, find Y

9. RETRIEVE CONTEXT
   â”œâ”€â†’ BROAD QUERY: Use full transcript_cache
   â””â”€â†’ SPECIFIC: Vector similarity search
       â”œâ”€â†’ Query embedded via ada-002
       â”œâ”€â†’ Pinecone searches top-6 similar chunks
       â””â”€â†’ Ranked by cosine similarity

10. GENERATE ANSWER
    â”œâ”€â†’ Retrieve chat history from session_id
    â”œâ”€â†’ Build prompt: {history, context, question}
    â”œâ”€â†’ chain_with_memory.invoke()
    â”œâ”€â†’ GPT-4o-mini generates response
    â””â”€â†’ COST: ~$0.005 per query (after first)

11. RETURN RESPONSE
    â””â”€â†’ {"answer": "This video is about..."}

12. BACKGROUND WORKER RECEIVES
    â””â”€â†’ Sends response back to content.js

13. CONTENT SCRIPT RENDERS
    â”œâ”€â†’ Updates DOM with answer
    â””â”€â†’ Optional: Synthesize voice output (Web Speech API)

14. USER SEES ANSWER
    â””â”€â†’ Answer displayed in floating widget
    â””â”€â†’ Audio plays if voice enabled
```

### Transcript Acquisition Workflow

```
Start: get_transcript(video_id, video_url)
  â”‚
  â”œâ”€â†’ TRY: youtube-transcript-api.fetch(video_id)
  â”‚   â”‚
  â”‚   â”œâ”€â†’ SUCCESS: Return [{text, start, duration}, ...]
  â”‚   â”‚   COST: Free
  â”‚   â”‚   TIME: <1 second
  â”‚   â”‚   SUCCESS RATE: ~80% of videos
  â”‚   â”‚
  â”‚   â””â”€â†’ TranscriptsDisabled Exception:
  â”‚       â”‚
  â”‚       â””â”€â†’ EXCEPT: Proceed to ASR fallback
  â”‚
  â””â”€â†’ FALLBACK: Use Whisper ASR
      â”‚
      â”œâ”€â†’ yt-dlp downloads best audio
      â”‚   COST: Free
      â”‚   TIME: 5-15 seconds
      â”‚
      â”œâ”€â†’ Check audio file size
      â”‚   â”‚
      â”‚   â”œâ”€â†’ <25 MB: Transcribe directly
      â”‚   â”‚   TIME: Few seconds
      â”‚   â”‚
      â”‚   â””â”€â†’ >=25 MB: Split into 5-min chunks
      â”‚       â”œâ”€â†’ COST per chunk: Free (Whisper is open-source)
      â”‚       â”œâ”€â†’ TIME per chunk: 30-60 seconds
      â”‚       â””â”€â†’ Merge with timestamp adjustments
      â”‚
      â””â”€â†’ Return transformed segments: [{text, start, duration}, ...]
          TOTAL TIME for 1-hour video: 5-10 minutes
```

---

## Setup & Installation

### Prerequisites

- **Python 3.8+** (3.10+ recommended)
- **Chrome/Chromium** browser
- **API Keys**: OpenAI, Pinecone (free tier available)
- **Internet connection** (for external APIs)

### Backend Installation

#### 1. Clone & Navigate

```bash
git clone https://github.com/gargdivyansh1/YouTube_Assistant.git
cd YouTube_Assistant
```

#### 2. Create Virtual Environment

```bash
# Windows
python -m venv venv
venv\Scripts\activate

# macOS/Linux
python3 -m venv venv
source venv/bin/activate
```

#### 3. Install Dependencies

```bash
cd backend
pip install -r requirements.txt
```

**Required packages**:
- fastapi, uvicorn, pydantic (web framework)
- langchain, langchain-openai, langchain-pinecone (LLM orchestration)
- openai, pinecone-client (APIs)
- youtube-transcript-api, yt-dlp, faster-whisper, pydub (media processing)
- python-dotenv (configuration)

#### 4. Get API Keys

**OpenAI** (for GPT-4o-mini + embeddings):
1. Visit https://platform.openai.com/api-keys
2. Create new secret key (select "All" permissions)
3. Copy key (starts with `sk-proj-`)

**Pinecone** (for vector database):
1. Visit https://console.pinecone.io
2. Create API key (free tier: 1 index, 100K vectors)
3. Note your region (us-east-1 recommended)
4. Copy key (starts with `pcak_`)

#### 5. Configure Environment

```bash
# From project root (not backend/)
cp .env.sample .env
```

Edit `.env`:

```bash
# Required - Get from above
OPENAI_API_KEY=sk-proj-YOUR_KEY_HERE
PINECONE_API_KEY=pcak_YOUR_KEY_HERE

# Optional - Defaults work fine
BACKEND_HOST=127.0.0.1
BACKEND_PORT=8000
```

#### 6. Start Backend

```bash
# From backend directory
python index.py
```

**Expected output**:
```
INFO:     Uvicorn running on http://127.0.0.1:8000
INFO:     Application startup complete
```

**Test it**:
```bash
curl http://127.0.0.1:8000/uptime
# Should return: {"status": "alive"}
```

### Chrome Extension Installation

#### 1. Open Extensions

1. Open Chrome
2. Type `chrome://extensions` in address bar
3. Toggle "Developer Mode" (top-right corner)

#### 2. Load Extension

1. Click "Load Unpacked"
2. Navigate to `youtube_assistant/chrome_extension/`
3. Click "Select Folder"

**Expected**: Extension appears in list with icon

#### 3. Verify

1. Go to any YouTube video: https://youtu.be/dQw4w9WgXcQ
2. Look for floating widget (bottom-right corner)
3. Widget shows "YouTube AI Assistant" header

#### 4. Test

1. Type question in widget: "What is this video about?"
2. Click "Ask" button
3. Wait 5-10 seconds (first request = slower due to transcript fetching)
4. Answer should appear in answer area

---

## Configuration

### Backend Configuration (.env)

#### Required

```bash
OPENAI_API_KEY=sk-proj-xxxxxxxxxxxx
PINECONE_API_KEY=pcak_xxxxxxxxxxxx
```

#### Optional

```bash
# Server
BACKEND_HOST=0.0.0.0           # For production: set specific IP
BACKEND_PORT=8000              # Change if port already in use

# OpenAI
OPENAI_MODEL=gpt-4o-mini       # Options: gpt-4, gpt-3.5-turbo, gpt-4o-mini
OPENAI_TEMPERATURE=0            # 0=deterministic, 1=creative

# Pinecone
PINECONE_REGION=us-east-1      # Match your region
PINECONE_INDEX=youtube-assistant  # Custom index name

# Transcript
TRANSCRIPT_CHUNK_SIZE=400       # Characters per chunk
TRANSCRIPT_CHUNK_OVERLAP=50     # Character overlap
RETRIEVER_K=6                   # Results returned per query

# Audio
AUDIO_CHUNK_LENGTH=300000       # Milliseconds (5 min)
WHISPER_MODEL=tiny              # Options: tiny, base, small, medium, large
```

### Extension Configuration

Edit `chrome_extension/background.js`:

```javascript
// Line ~5
const BACKEND_URL = "http://127.0.0.1:8000/chat";

// Change for production:
// const BACKEND_URL = "https://your-api.com/chat";
```

---

## API Reference

### POST /chat

**Submit question and receive AI-generated answer**

**Endpoint**: `POST http://localhost:8000/chat`

**Request Body**:
```json
{
  "session_id": "user_123_video_456",
  "question": "What is this video about?",
  "video_id": "dQw4w9WgXcQ"
}
```

| Parameter | Type | Required | Description |
|-----------|------|----------|-------------|
| `session_id` | string | âœ… | Unique per user-video pair; enables chat memory |
| `question` | string | âœ… | User's question |
| `video_id` | string | âœ… | 11-character YouTube ID |

**Response**:
```json
{
  "answer": "This video is a humorous Rick Astley music video..."
}
```

**Status Codes**:
- `200`: Success
- `400`: Invalid request parameters
- `500`: Server error (transcript unavailable, API timeout)

**Example**:
```bash
curl -X POST http://127.0.0.1:8000/chat \
  -H "Content-Type: application/json" \
  -d '{
    "session_id": "user_divya_video_abc",
    "question": "Summarize this",
    "video_id": "dQw4w9WgXcQ"
  }'
```

### HEAD /uptime

**Health check for keep-alive**

**Endpoint**: `HEAD http://localhost:8000/uptime`

**Response**: `{"status": "alive"}`

---

## Advanced Topics

### Session Management & Chat Memory

Each `session_id` maintains separate conversation history:

```python
store = {}

def get_session_history(session_id: str):
    if session_id not in store:
        store[session_id] = InMemoryChatMessageHistory()
    return store[session_id]
```

**Example**:
```json
POST 1: {session_id: "user_divya", question: "What's this about?"}
â†’ Answer: "This is about machine learning..."

POST 2: {session_id: "user_divya", question: "Can you explain XGBoost?"}
â†’ Answer uses history: "Based on what we discussed, XGBoost is..."
```

**Note**: History cleared on backend restart. For persistence, use PostgreSQL/Redis.

### Customizing System Prompts

Edit `backend/main.py` (lines ~150-170):

```python
prompt = ChatPromptTemplate.from_template("""
You are a helpful and intelligent AI assistant...
[CUSTOMIZE INSTRUCTIONS HERE]
Your goal is to provide accurate, thoughtful responses...
""")
```

### Optimizing Vector Search

**Adjust number of retrieved chunks**:
```python
# In index.py, change:
search_kwargs={'k': 6}  # More = better context, higher cost
# Options: k=3 (fast), k=6 (balanced), k=12 (comprehensive)
```

**Use Maximum Marginal Relevance (MMR)**:
```python
vectorstore.as_retriever(
    search_type='mmr',
    search_kwargs={'k': 6, 'lambda_mult': 0.5}
)
# Reduces redundancy in results
```

---

## Troubleshooting

### Backend Connection Error

**Symptom**: "Error connecting to backend"

**Solution**:
```bash
# 1. Verify backend is running
curl http://127.0.0.1:8000/uptime

# 2. Check port is not in use (Windows)
netstat -ano | findstr :8000

# 3. Restart backend
cd backend && python index.py

# 4. Verify extension has correct URL
# Edit chrome_extension/background.js
```

### No Transcript Available

**Symptom**: "No transcript available for this video"

**Causes**: Video has no captions AND audio download failed

**Solution**:
```bash
# 1. Update yt-dlp
pip install --upgrade yt-dlp

# 2. Test video is downloadable
yt-dlp https://www.youtube.com/watch?v=VIDEO_ID

# 3. Verify faster-whisper
python -c "from faster_whisper import WhisperModel; print('OK')"
```

### Invalid API Key

**Symptom**: Error about invalid OPENAI_API_KEY or PINECONE_API_KEY

**Solution**:
```bash
# 1. Verify .env exists in project root (not backend/)
ls -la .env

# 2. Check format
# OpenAI: sk-proj-XXXXX (starts with sk-proj-)
# Pinecone: pcak_XXXXX (starts with pcak_)

# 3. Test keys
python -c "
import os
from dotenv import load_dotenv
load_dotenv()
print('OpenAI:', os.getenv('OPENAI_API_KEY')[:10])
print('Pinecone:', os.getenv('PINECONE_API_KEY')[:10])
"
```

### Response Times Too Long

**Symptom**: Waiting >30 seconds for answer

**This is normal for**:
- First request (includes transcript download): 30-60 seconds
- Videos with slow ASR: 5-10+ minutes for 1-hour video

**Subsequent requests**: <5 seconds (cached)

### CORS Errors

**Symptom**: Console shows CORS error

**Solution**:
```bash
# Backend already has allow_origins=["*"]
# If error persists, clear extension cache:
# chrome://extensions â†’ Details â†’ {Extension Name} â†’ Clear browsing data
```

---

## Contributing

### How to Contribute

1. **Fork repository**
   ```bash
   git clone https://github.com/YOUR_USERNAME/YouTube_Assistant.git
   cd YouTube_Assistant
   git checkout -b feature/your-feature-name
   ```

2. **Make changes**
   - Follow PEP 8 for Python
   - Add comments for complex logic
   - Test on actual YouTube videos

3. **Commit**
   ```bash
   git commit -m "feat: add language support for German"
   ```

4. **Push & Create PR**
   ```bash
   git push origin feature/your-feature-name
   ```

### Types of Contributions Welcome

- ğŸ› **Bug Fixes**: Fix existing issues
- âœ¨ **Features**: New capabilities (export chat, language support, etc.)
- âš¡ **Performance**: Optimize latency, cost, accuracy
- ğŸ“š **Documentation**: Improve README, add examples, guides
- âœ… **Testing**: Unit tests, integration tests

---

## Acknowledgements

**Core Technologies**:
- [OpenAI](https://openai.com/) - GPT-4o-mini LLM + text-embedding-ada-002
- [Pinecone](https://www.pinecone.io/) - Serverless vector database
- [LangChain](https://github.com/langchain-ai/langchain) - LLM orchestration
- [FastAPI](https://fastapi.tiangolo.com/) - Web framework
- [Whisper ASR](https://github.com/openai/whisper) - Speech recognition

**Supporting Libraries**:
- [youtube-transcript-api](https://github.com/jderose9/youtube-transcript-api)
- [yt-dlp](https://github.com/yt-dlp/yt-dlp)  
- [faster-whisper](https://github.com/SYSTRAN/faster-whisper)
- [pydub](https://github.com/jiaaro/pydub)
- [Uvicorn](https://www.uvicorn.org/)

**Community**: Thanks to all contributors and users! ğŸ™

---

## License

MIT License - See LICENSE file for details

---

## Support

- ğŸ“– [Detailed Technical Guide](README_DETAILED.md) - Deep dive into architecture
- ğŸ› [GitHub Issues](https://github.com/gargdivyansh1/YouTube_Assistant/issues) - Report bugs
- ğŸ’¬ [Discussions](https://github.com/gargdivyansh1/YouTube_Assistant/discussions) - Ask questions
- ğŸ“§ **Email**: Contact project maintainers

---

**Version**: 1.0.0 | **Updated**: February 12, 2026

**ğŸš€ Ready to revolutionize your YouTube experience?**

*Start by running your backend, loading the extension, and asking a question about your favorite YouTube video!*
